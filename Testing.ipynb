{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LDA():\n",
    "    _feat = None\n",
    "    _targ = None\n",
    "    _N = None\n",
    "    _p_one = None\n",
    "    _p_zero = None\n",
    "    _u_one = None\n",
    "    _u_zero = None\n",
    "    _E_one = None\n",
    "    _E_zero = None\n",
    "    _E = None\n",
    "    def __init__(self,features,targets):\n",
    "        self._feat = features\n",
    "        self._targ = targets\n",
    "        self._N = targets.size #Expecting 1d Array of labels\n",
    "        self._n_one = targets.sum()\n",
    "        self._n_zero = (self._N-self._targ.sum())\n",
    "        self._p_one = self._n_one/self._N\n",
    "        self._p_zero = self._n_zero/self._N\n",
    "        self._u_zero = 0\n",
    "        self._u_one = 0\n",
    "        for x in range(self._N): ##INDICATOR\n",
    "            if self._targ[x] == 1:\n",
    "                self._u_one += self._feat[x]\n",
    "            else:\n",
    "                self._u_zero += self._feat[x]\n",
    "        self._u_zero = self._u_zero/self._n_zero #Expecting 1/0 labels passed on\n",
    "        self._u_one = self._u_one/self._n_one\n",
    "        self._E_one =0\n",
    "        self._E_zero =0\n",
    "        for x in range(self._N):\n",
    "            if self._targ[x] == 1:\n",
    "                self._E_one += np.outer((self._feat[x] - self._u_one),(self._feat[x] - self._u_one))/(self._N -2)\n",
    "            else:\n",
    "                self._E_zero += np.outer((self._feat[x] - self._u_zero),(self._feat[x] - self._u_zero))/(self._N -2)\n",
    "        self._E = self._E_one + self._E_zero\n",
    "\n",
    "    def predict(self,features):\n",
    "        predResult = []\n",
    "        a = np.log(self._p_one/self._p_zero)\n",
    "        b = (np.dot(np.dot(self._u_one.T,np.linalg.inv(np.array(self._E,dtype=np.float32))),self._u_one)/2) # Bit weird to explain why I didnt power by -1\n",
    "        print(b)\n",
    "        c = (np.dot(np.dot(self._u_zero.T,np.linalg.inv(np.array(self._E,dtype=np.float32))),self._u_zero)/2)\n",
    "        print(c)\n",
    "        for x in range(features.shape[0]):\n",
    "            d = np.dot(np.dot(features[x].T,np.linalg.inv(np.array(self._E,dtype=np.float32))),(self._u_one-self._u_zero))\n",
    "#            d = ((features[x].T*np.power(self._E,-1)*(self._u_one-self._u_zero)))\n",
    "            res = a-b+c+d\n",
    "            if res > 0:\n",
    "                predResult.append(1)\n",
    "            else:\n",
    "                predResult.append(0)\n",
    "            \n",
    "        return np.array(predResult)\n",
    "    \n",
    "    def Accu_eval(self,pL,tL):\n",
    "        n=tL.size\n",
    "        print(tL,pL)\n",
    "        return np.mean(pL == tL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218.659820869128\n",
      "1246.094612848161\n",
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1] [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1]\n",
      "0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    #Attributes\n",
    "    _features = None\n",
    "    _targets = None\n",
    "    _weights = None\n",
    "    featt = None\n",
    "    tarr = None\n",
    "    \n",
    "    def __init__(self, feat,target):\n",
    "        #TARGET IS EXPECTED TO BE changed to 1d array of 1 and zeros\n",
    "        feat = np.insert(feat,0,1,axis=1) ##Adding x^0\n",
    "        self._features = feat\n",
    "        self._weights = np.zeros(self._features[0].size)\n",
    "        self._targets = target\n",
    "        self.tarr = self._targets.flatten()\n",
    "        self.featt = self._features\n",
    "\n",
    "    def fit(self, tData, corVec, lRate, itera): \n",
    "        for x in range(itera):\n",
    "            N = tData.shape[0]\n",
    "            grad = np.dot((corVec-self.sig(np.dot(tData,self._weights))),tData) \n",
    "            grad *= lRate\n",
    "            grad /= N\n",
    "            self._weights = np.add(self._weights,grad)\n",
    "\n",
    "\n",
    "    def predict(self,tSet):\n",
    "        return self._classify(self.sig(np.array(np.dot(tSet, self._weights),dtype=np.float32)))\n",
    "    \n",
    "    def cost(self,trueV,predV):\n",
    "        obs = trueV.shape[0]\n",
    "        \n",
    "        return ((-trueV*np.log(predV))-((1-trueV)*np.log(1-predV))).sum()/obs\n",
    "    def sig(self,r):\n",
    "        return 1.0/(1.0+np.exp(-(np.array(r,dtype=np.float32))))\n",
    "    \n",
    "    def printW(self):\n",
    "        return self._weights\n",
    "    def _classify(self,pred):\n",
    "        l = []\n",
    "        for x in pred:\n",
    "            if x >= 0.5:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "        return np.array(l)\n",
    "        \n",
    "    def Accu_eval(self,pL,tL):\n",
    "        n=tL.size\n",
    "        return np.mean(pL == tL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('parkinsons.csv')\n",
    "df2 = pd.read_csv('sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_y = df1['status']\n",
    "df1_x = df1.drop(['name', 'status'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1_x, df1_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03148674964904785 seconds for Logistic Regression prediction ---\n",
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "lr_clf = LogisticRegression(np.array(X_train), np.array(y_train))\n",
    "lr_clf.fit(lr_clf.featt,lr_clf.tarr,0.3,1000)\n",
    "pred = lr_clf.predict(np.insert(np.array(X_test),0,1,axis=1))\n",
    "print(\"--- %s seconds for Logistic Regression prediction ---\" % (time.time() - start_time))\n",
    "print(lr_clf.Accu_eval(pred, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153.2558031932604\n",
      "1176.508625973147\n",
      "--- 0.005982160568237305 seconds for LDA prediction ---\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1\n",
      " 0 0] [1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1]\n",
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "start_time1 = time.time()\n",
    "lda_clf = LDA(np.array(X_train), np.array(y_train))\n",
    "pred = lda_clf.predict(np.array(X_test))\n",
    "print(\"--- %s seconds for LDA prediction ---\" % (time.time() - start_time1))\n",
    "print(lda_clf.Accu_eval(np.array(pred), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()\n",
    "df2_y = df2['R']\n",
    "df2_x = df2.drop(['R'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoding = {'R' : 1, 'M' : 0}\n",
    "df2_y.replace(binary_encoding, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.02096080780029297 seconds for Logistic Regression prediction ---\n",
      "0.8095238095238095\n",
      "57.145884065421\n",
      "64.58266473990804\n",
      "--- 0.01798272132873535 seconds for LDA prediction ---\n",
      "[1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1] [1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0]\n",
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2_x, df2_y, test_size=0.2)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_clf = LogisticRegression(np.array(X_train), np.array(y_train))\n",
    "lr_clf.fit(lr_clf.featt,lr_clf.tarr,0.3,1000)\n",
    "pred = lr_clf.predict(np.insert(np.array(X_test),0,1,axis=1))\n",
    "print(\"--- %s seconds for Logistic Regression prediction ---\" % (time.time() - start_time))\n",
    "print(lr_clf.Accu_eval(pred, np.array(y_test)))\n",
    "\n",
    "\n",
    "start_time1 = time.time()\n",
    "lda_clf = LDA(np.array(X_train), np.array(y_train))\n",
    "pred = lda_clf.predict(np.array(X_test))\n",
    "print(\"--- %s seconds for LDA prediction ---\" % (time.time() - start_time1))\n",
    "print(lda_clf.Accu_eval(np.array(pred), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.2, 0.3, 0.01, 0.02, 0.05, 0.001, 0.0001]\n",
    "def test_logreg_lrs(X_train, X_test, y_train, y_test, lrs):\n",
    "    for lr in lrs:\n",
    "        start_time = time.time()\n",
    "        lr_clf = LogisticRegression(np.array(X_train), np.array(y_train))\n",
    "        print(\"Testing Learning rate: \", lr)\n",
    "        lr_clf.fit(lr_clf.featt,lr_clf.tarr,lr, 1000)\n",
    "        pred = lr_clf.predict(np.insert(np.array(X_test),0,1,axis=1))\n",
    "        print(\"--- %s seconds for Logistic Regression prediction ---\" % (time.time() - start_time))\n",
    "        print(lr_clf.Accu_eval(pred, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Learning rate:  0.1\n",
      "--- 0.019970178604125977 seconds for Logistic Regression prediction ---\n",
      "0.8095238095238095\n",
      "Testing Learning rate:  0.2\n",
      "--- 0.016956090927124023 seconds for Logistic Regression prediction ---\n",
      "0.8095238095238095\n",
      "Testing Learning rate:  0.3\n",
      "--- 0.018957853317260742 seconds for Logistic Regression prediction ---\n",
      "0.8095238095238095\n",
      "Testing Learning rate:  0.01\n",
      "--- 0.014959573745727539 seconds for Logistic Regression prediction ---\n",
      "0.6666666666666666\n",
      "Testing Learning rate:  0.02\n",
      "--- 0.01395726203918457 seconds for Logistic Regression prediction ---\n",
      "0.7857142857142857\n",
      "Testing Learning rate:  0.05\n",
      "--- 0.015074491500854492 seconds for Logistic Regression prediction ---\n",
      "0.7857142857142857\n",
      "Testing Learning rate:  0.001\n",
      "--- 0.0 seconds for Logistic Regression prediction ---\n",
      "0.5238095238095238\n",
      "Testing Learning rate:  0.0001\n",
      "--- 0.0156402587890625 seconds for Logistic Regression prediction ---\n",
      "0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "test_logreg_lrs(X_train, X_test, y_train, y_test, learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Learning rate:  0.1\n",
      "--- 0.022917747497558594 seconds for Logistic Regression prediction ---\n",
      "0.8205128205128205\n",
      "Testing Learning rate:  0.2\n",
      "--- 0.02695488929748535 seconds for Logistic Regression prediction ---\n",
      "0.2564102564102564\n",
      "Testing Learning rate:  0.3\n",
      "--- 0.019917964935302734 seconds for Logistic Regression prediction ---\n",
      "0.8205128205128205\n",
      "Testing Learning rate:  0.01\n",
      "--- 0.014914989471435547 seconds for Logistic Regression prediction ---\n",
      "0.1794871794871795\n",
      "Testing Learning rate:  0.02\n",
      "--- 0.019982099533081055 seconds for Logistic Regression prediction ---\n",
      "0.8205128205128205\n",
      "Testing Learning rate:  0.05\n",
      "--- 0.02023029327392578 seconds for Logistic Regression prediction ---\n",
      "0.1794871794871795\n",
      "Testing Learning rate:  0.001\n",
      "--- 0.008060932159423828 seconds for Logistic Regression prediction ---\n",
      "0.8205128205128205\n",
      "Testing Learning rate:  0.0001\n",
      "--- 0.015620708465576172 seconds for Logistic Regression prediction ---\n",
      "0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1_x, df1_y, test_size=0.2)\n",
    "test_logreg_lrs(X_train, X_test, y_train, y_test, learning_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_df = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
       "       'spread1', 'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinsons_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_new = parkinsons_df.loc[:, ['MDVP:Jitter(%)','spread1', 'spread2', 'D2', 'PPE', 'RPDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_y = parkinsons_df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(parkinsons_new, parkinsons_y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.015971899032592773 seconds for Logistic Regression prediction ---\n",
      "0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr_clf = LogisticRegression(np.array(X_train), np.array(y_train))\n",
    "lr_clf.fit(lr_clf.featt,lr_clf.tarr,0.3,1000)\n",
    "pred = lr_clf.predict(np.insert(np.array(X_test),0,1,axis=1))\n",
    "print(\"--- %s seconds for Logistic Regression prediction ---\" % (time.time() - start_time))\n",
    "print(lr_clf.Accu_eval(pred, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487.7736169411521\n",
      "503.8918588132939\n",
      "--- 0.016470670700073242 seconds for LDA prediction ---\n",
      "[1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
      " 1 0] [1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1]\n",
      "0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "start_time1 = time.time()\n",
    "lda_clf = LDA(np.array(X_train), np.array(y_train))\n",
    "pred = lda_clf.predict(np.array(X_test))\n",
    "print(\"--- %s seconds for LDA prediction ---\" % (time.time() - start_time1))\n",
    "print(lda_clf.Accu_eval(np.array(pred), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
